{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTraining:\n",
    "    def __init__(self, classifier):\n",
    "        if sklearn.base.is_classifier(classifier):\n",
    "            self.classifiers = [sklearn.base.clone(classifier) for i in range(3)]\n",
    "        else:\n",
    "            self.classifiers = [sklearn.base.clone(classifier[i]) for i in range(3)]\n",
    "            \n",
    "    def fit(self, L_X, L_y, U_X):\n",
    "            \n",
    "        for i in range(3):\n",
    "            sample = sklearn.utils.resample(L_data, L_label)  # BootstrapSample(L)\n",
    "            self.classifiers[i].fit(*sample)  # Learn(Si)   \n",
    "        e_prime = [0.5]*3\n",
    "        l_prime = [0]*3\n",
    "        e = [0]*3\n",
    "        update = [False]*3\n",
    "        Li_X, Li_y = [[]]*3, [[]]*3#to save proxy labeled data\n",
    "        improve = True\n",
    "        self.iter = 0\n",
    "        \n",
    "        while improve:\n",
    "            self.iter += 1#count iterations \n",
    "            \n",
    "            for i in range(3):    \n",
    "                j, k = np.delete(np.array([0,1,2]),i)\n",
    "                update[i] = False\n",
    "                e[i] = self.measure_error(L_X, L_y, j, k)\n",
    "                if e[i] < e_prime[i]:\n",
    "                    U_y_j = self.classifiers[j].predict(U_data)\n",
    "                    U_y_k = self.classifiers[k].predict(U_data)\n",
    "                    Li_X[i] = U_X[U_y_j == U_y_k]#when two models agree on the label, save it\n",
    "                    Li_y[i] = U_y_j[U_y_j == U_y_k]\n",
    "                    if l_prime[i] == 0:#no updated before\n",
    "                        l_prime[i]  = int(e[i]/(e_prime[i] - e[i]) + 1)\n",
    "                    if l_prime[i] <len(Li_y[i]):\n",
    "                        if e[i]*len(Li_y[i])<e_prime[i] * l_prime[i]:\n",
    "                            update[i] = True\n",
    "                        elif l_prime[i] > e[i]/(e_prime[i] - e[i]):\n",
    "                            L_index = np.random.choice(len(Li_y[i]), int(e_prime[i] * l_prime[i]/e[i] -1))#subsample from proxy labeled data\n",
    "                            Li_X[i], Li_y[i] = Li_X[i][L_index], Li_y[i][L_index]\n",
    "                            update[i] = True\n",
    "             \n",
    "            for i in range(3):\n",
    "                if update[i]:\n",
    "                    self.classifiers[i].fit(np.append(L_X,Li_X[i],axis=0), np.append(L_y, Li_y[i], axis=0))#train the classifier on integrated dataset\n",
    "                    e_prime[i] = e[i]\n",
    "                    l_prime[i] = len(Li_y[i])\n",
    "    \n",
    "            if update == [False]*3:\n",
    "                improve = False#if no classifier was updated, no improvement\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.asarray([self.classifiers[i].predict(X) for i in range(3)])\n",
    "        pred[0][pred[1]==pred[2]] = pred[1][pred[1]==pred[2]]\n",
    "        return pred[0]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n",
    "        \n",
    "    def measure_error(self, X, y, j, k):\n",
    "        j_pred = self.classifiers[j].predict(X)\n",
    "        k_pred = self.classifiers[k].predict(X)\n",
    "        wrong_index =np.logical_and(j_pred != y, k_pred==j_pred)#model_j and model_k make the same wrong prediction\n",
    "        #wrong_index =np.logical_and(j_pred != y_test, k_pred!=y_test)\n",
    "        return sum(wrong_index)/sum(j_pred == k_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38708/3637842863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mL_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#m = TriTraining(classifier['DecisionTree'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_process' is not defined"
     ]
    }
   ],
   "source": [
    "L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], r)\n",
    "\n",
    "classifiers = [sklearn.base.clone(classifier[i]) for i in classifier.keys()]\n",
    "\n",
    "#m = TriTraining(classifier['DecisionTree'])\n",
    "m = TriTraining(classifiers)\n",
    "\n",
    "m.fit(L_data, L_label, U_data)\n",
    "print(m.classifiers)\n",
    "m.score( X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfTraining:\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = sklearn.base.clone(classifier)\n",
    "    \n",
    "    def fit(self, L_X, L_y, U_X, tau):\n",
    "        improve =  True\n",
    "        self.iter = 0\n",
    "        while improve and len(U_X) !=0:\n",
    "            self.classifier.fit(L_X, L_y)\n",
    "            U_prob = self.classifier.predict_proba(U_X)\n",
    "            U_label = self.classifier.predict(U_X)\n",
    "            label_index = np.argmax(U_prob, axis = 1)>tau\n",
    "\n",
    "            if sum(label_index) ==0:\n",
    "                improve = False\n",
    "            self.iter += 1\n",
    "            L_X = np.append(L_X, U_X[label_index], axis=0)\n",
    "            L_y = np.append(L_y, U_label[label_index])\n",
    "            U_X = np.delete(U_X, np.where(label_index), axis=0)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTrainingwDisagreement():\n",
    "\n",
    "    def __init__(self, classifier):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            classifier - classifier, with .fit, .predict API (refer to classifiers of sklearn)\n",
    "        \"\"\"\n",
    "        # Initialize\n",
    "        if sklearn.base.is_classifier(classifier):\n",
    "            self.clf = [sklearn.base.clone(classifier) for i in range(3)]\n",
    "        else:\n",
    "            self.clf = [sklearn.base.clone(classifier[i]) for i in range(3)]\n",
    "\n",
    "    def measure_error(self, j, k):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                j - int, classifier index\n",
    "                k - int, classifier index\n",
    "        return:\n",
    "                float, classification_error\n",
    "        \"\"\"\n",
    "        y_predict_j = self.clf[j].predict(self.X_label)\n",
    "        y_predict_k = self.clf[k].predict(self.X_label)\n",
    "        return (1 - np.sum((y_predict_j == y_predict_k) & (y_predict_j == self.y_label)) / np.sum(y_predict_j == y_predict_k))\n",
    "\n",
    "    def fit(self, X_label, y_label, X_unlabel):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_label - labeled train feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_label - labeled train label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "                X_unlabel - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        \"\"\"        \n",
    "\n",
    "        self.X_label = X_label\n",
    "        self.y_label = y_label\n",
    "\n",
    "        classification_error_current = [0.5, 0.5, 0.5]\n",
    "        classification_error = [0.5, 0.5, 0.5]\n",
    "        pseudo_label_size_current = [0, 0, 0]\n",
    "        pseudo_label_size = [0, 0, 0]\n",
    "        # pseudo_label_index used to compare and check if tri-training can be stopped, when two iterations have the same label_index, means tri-training can be stopped\n",
    "        X_pseudo_label_index = [[], [], []]\n",
    "        X_pseudo_label_index_current = [[], [], []]\n",
    "\n",
    "        feature_size = self.X_label.shape[1]\n",
    "\n",
    "        # Train each classifier with bootstrampped subset\n",
    "        for i in range(3):\n",
    "            X_resample, y_resample = sklearn.utils.resample(self.X_label, self.y_label)  # BootstrapSample(L)\n",
    "            self.clf[i].fit(X_resample, y_resample)  # Learn(Si)\n",
    "\n",
    "        iteration = 0\n",
    "        while (True):\n",
    "\n",
    "            update = [False, False, False]\n",
    "\n",
    "            iteration = iteration + 1\n",
    "            for i in range(3):\n",
    "                X_pseudo_label_index_current[i] = X_pseudo_label_index[i]\n",
    "\n",
    "            # Step3.1 Set Li = empty set, Li denotes the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label_index, contains the data record index (in the full unlabelled set) of the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label, contains the features for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # y_pseudo_label, contains the labels (not ground truth label, but pseudo label calculated by tri-training iteration) for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            X_pseudo_label_index = [[], [], []]\n",
    "            X_pseudo_label = [[], [], []]\n",
    "            y_pseudo_label = [[], [], []]\n",
    "\n",
    "            # Step 3.2 Loop through all the data record in unlabelled set\n",
    "            for i in range(3):\n",
    "                j, k = np.delete(np.array([0, 1, 2]), i)\n",
    "                classification_error[i] = self.measure_error(j, k)\n",
    "                if classification_error[i] < classification_error_current[i]:\n",
    "                    # Step 3.2 If classifier j,k aggrees with the label for one data record, and not agree with classifier i, in unlabelled set,\n",
    "                    # then add the data record into Li                    \n",
    "                    y_predict_j = self.clf[j].predict(X_unlabel)\n",
    "                    y_predict_k = self.clf[k].predict(X_unlabel)\n",
    "                    y_predict_i = self.clf[i].predict(X_unlabel)\n",
    "                    y_pseudo_label[i] = y_predict_j[np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i)]\n",
    "                    X_pseudo_label_index[i] = np.where(np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i))\n",
    "                    \n",
    "                    pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                    #print(\"classification_error: {}, classification_error_current: {}, pseudo_label_size: {}, pseudo_label_size_current: {}\".format(classification_error[i], classification_error_current[i], pseudo_label_size[i],pseudo_label_size_current[i]))\n",
    "\n",
    "                    if pseudo_label_size_current[i] == 0:\n",
    "                        pseudo_label_size_current[i] = math.floor(classification_error[i] / (classification_error_current[i] - classification_error[i]) + 1)\n",
    "                    if pseudo_label_size_current[i] < pseudo_label_size[i]:\n",
    "                        if ((classification_error[i] * pseudo_label_size[i]) < (classification_error_current[i] * pseudo_label_size_current[i])):\n",
    "                            update[i] = True\n",
    "                        elif pseudo_label_size_current[i] > (classification_error[i] / (classification_error_current[i] - classification_error[i])):\n",
    "                            resample_size = math.ceil(classification_error_current[i] * pseudo_label_size_current[i] / classification_error[i] - 1)\n",
    "                            X_pseudo_label_index[i], y_pseudo_label[i] = sklearn.utils.resample(X_pseudo_label_index[i],y_pseudo_label[i],replace=False,n_samples=resample_size)\n",
    "                            pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                            update[i] = True\n",
    "\n",
    "            # Step 3.3 Train all the three classifiers with Li + original labelled data set\n",
    "            for i in range(3):\n",
    "                if update[i] == True:\n",
    "                    #print(\"number of pseudo labels added for classifier {} is: {}\".format(i,len(X_pseudo_label_index[i])))\n",
    "                    X_pseudo_label[i] = np.array(X_unlabel[X_pseudo_label_index[i]])\n",
    "                    self.clf[i].fit(np.concatenate((X_pseudo_label[i], self.X_label), axis=0),np.concatenate((np.array(y_pseudo_label[i]), self.y_label), axis=0))\n",
    "                    classification_error_current[i] = classification_error[i]\n",
    "                    pseudo_label_size_current[i] = pseudo_label_size[i]\n",
    "\n",
    "            # Stop tri-training process, if the pseudo label data set added in current tri-training iteration\n",
    "            # is the same for last tri-training iteration for all classifiers\n",
    "            if (np.array_equal(X_pseudo_label_index[0], X_pseudo_label_index_current[0]) & np.array_equal(X_pseudo_label_index[1], X_pseudo_label_index_current[1]) \n",
    "                    & np.array_equal(X_pseudo_label_index[2], X_pseudo_label_index_current[2])):\n",
    "                break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        return:\n",
    "                array of size (# of test samples), with values as predicted label 1 or 0\n",
    "        \"\"\"\n",
    "        I = self.clf[0].predict(X_test)\n",
    "        J = self.clf[1].predict(X_test)\n",
    "        K = self.clf[2].predict(X_test)\n",
    "        I[J == K] = J[J == K]\n",
    "        return I\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_test - test label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "        return:\n",
    "                float, accuracy_score of predicted value by the tri-training (with disagreement) classifier against groud truth\n",
    "        \"\"\"\n",
    "        \n",
    "        return sklearn.metrics.accuracy_score(y_test, self.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, label, rate, test_rate=0.25):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = test_rate, random_state=0)\n",
    "\n",
    "    rng = np.random.RandomState(0)#to make same index every time\n",
    "    labeled_index = rng.rand(len(y_train)) < rate#in training set, choose 20% as labeled data\n",
    "    unlabeled_index = np.logical_not(labeled_index)\n",
    "    L_data = X_train[labeled_index]#data of L\n",
    "    L_label = y_train[labeled_index]#lable of L\n",
    "    U_data = X_train[unlabeled_index]#data of U\n",
    "    return L_data, L_label, U_data, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = {}\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "classifier['DecisionTree'] = tree.DecisionTreeClassifier()\n",
    "#classifier['BP_Network'] = MLPClassifier(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(20, 10), random_state=1)\n",
    "classifier['NaiveBayes'] = GaussianNB()\n",
    "#classifier['SGD'] = linear_model.SGDClassifier(loss = 'hinge',max_iter=1000, tol=1e-3)\n",
    "classifier['SVM'] = svm.SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': array([[1.000e+00, 2.208e+01, 1.146e+01, ..., 2.000e+00, 1.000e+02,\n",
      "        1.213e+03],\n",
      "       [0.000e+00, 2.267e+01, 7.000e+00, ..., 2.000e+00, 1.600e+02,\n",
      "        1.000e+00],\n",
      "       [0.000e+00, 2.958e+01, 1.750e+00, ..., 2.000e+00, 2.800e+02,\n",
      "        1.000e+00],\n",
      "       ...,\n",
      "       [0.000e+00, 1.883e+01, 9.540e+00, ..., 2.000e+00, 1.000e+02,\n",
      "        1.000e+00],\n",
      "       [0.000e+00, 2.742e+01, 1.450e+01, ..., 2.000e+00, 1.200e+02,\n",
      "        1.200e+01],\n",
      "       [1.000e+00, 4.100e+01, 4.000e-02, ..., 1.000e+00, 5.600e+02,\n",
      "        1.000e+00]]), 'y': array([0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
      "       1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "       0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "       1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "       1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "       0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "       0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "       1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "       1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "       1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "       0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "       1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "       0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
      "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 1., 0., 1., 1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "\n",
    "data = np.loadtxt('australian.dat')[:, 0:14]\n",
    "label = np.loadtxt('australian.dat')[:, 14]\n",
    "dataset['australian'] = {'X': data, 'y':label}\n",
    "print(dataset['australian'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.16589595375722543\n",
      "TriTraining Disagree test error 0.15895953757225434\n",
      "SelfTraining test error 0.16271676300578033\n",
      "Supervised test error 0.17658959537572255 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.17543352601156073\n",
      "TriTraining Disagree test error 0.17485549132947978\n",
      "SelfTraining test error 0.18583815028901732\n",
      "Supervised test error 0.18872832369942197 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.15\n",
      "TriTraining Disagree test error 0.15693641618497112\n",
      "SelfTraining test error 0.15982658959537574\n",
      "Supervised test error 0.1569364161849711 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.1676300578034682\n",
      "TriTraining Disagree test error 0.15722543352601154\n",
      "SelfTraining test error 0.1508670520231214\n",
      "Supervised test error 0.17543352601156068 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.1875722543352601\n",
      "TriTraining Disagree test error 0.1647398843930636\n",
      "SelfTraining test error 0.1791907514450867\n",
      "Supervised test error 0.18497109826589594 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.26589595375722547\n",
      "TriTraining Disagree test error 0.2416184971098266\n",
      "SelfTraining test error 0.21387283236994215\n",
      "Supervised test error 0.26589595375722547 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.21676300578034677\n",
      "TriTraining Disagree test error 0.22023121387283234\n",
      "SelfTraining test error 0.20231213872832363\n",
      "Supervised test error 0.2196531791907514 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.21387283236994215\n",
      "TriTraining Disagree test error 0.21445086705202315\n",
      "SelfTraining test error 0.20809248554913298\n",
      "Supervised test error 0.21387283236994215 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: SVM\n",
      "label_rate: 0.2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38708/3966644777.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mm3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelfTraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mm3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mm4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mm4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38708/429521439.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, L_X, L_y, U_X, tau)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mimprove\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mU_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mU_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mlabel_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \"\"\"\n\u001b[1;32m--> 657\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    625\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    626\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:\n",
    "        for r in [0.2, 0.4, 0.6, 0.8]:        \n",
    "            print('dataset:', d, dataset[d]['X'].shape)\n",
    "            print('classifier:', c)\n",
    "            print('label_rate:', r)\n",
    "            error = np.zeros([4,20])\n",
    "            for i in range(20):#average on 20 data splits\n",
    "                L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], r)\n",
    "                m1 = TriTraining(classifier[c])\n",
    "                m1.fit(L_data, L_label, U_data)\n",
    "                m2 = TriTrainingwDisagreement(classifier[c])\n",
    "                m2.fit(L_data, L_label, U_data)\n",
    "                m3 = SelfTraining(classifier[c])\n",
    "                m3.fit(L_data, L_label, U_data, tau = 0.6)\n",
    "                m4 = sklearn.base.clone(classifier[c])\n",
    "                m4.fit(L_data, L_label)\n",
    "                error[0, i] = 1-m1.score(X_test, y_test)\n",
    "                error[1, i] = 1-m2.score(X_test, y_test)\n",
    "                error[2, i] = 1-m3.score(X_test, y_test)\n",
    "                error[3, i] = 1-m4.score(X_test, y_test)\n",
    "                \n",
    "            e = np.mean(error, axis = 1)\n",
    "\n",
    "            print('TriTraining test error', e[0])\n",
    "            print('TriTraining Disagree test error', e[1])\n",
    "            print('SelfTraining test error', e[2])\n",
    "            print('Supervised test error', e[3],'\\n')\n",
    "            \n",
    "            methods = ['Tri', 'Self', 'Sup']\n",
    "            test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "            errors = {'TriTraining': e[0], 'TriTraining Disagree': e[1], 'SelfTraining': e[2], 'Supervised': e[3]}#, 'Best': methods[np.argmin(e)]}#'\n",
    "            if results is None:\n",
    "                results = pd.DataFrame([{**test_info, **errors}])\n",
    "            else:\n",
    "                results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(results, values=None, index=['label_rate', 'classifier' ,'dataset' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Best'] = results.loc[:, ['TriTraining','SelfTraining', 'TriTraining Disagree', 'Supervised']].idxmin(axis = 1)\n",
    "results['Best'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
